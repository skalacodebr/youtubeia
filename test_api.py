#!/usr/bin/env python3
"""
Script para testar conexÃ£o com APIs compatÃ­veis com OpenAI
"""
import os
from openai import OpenAI

def test_openai_compatible_api():
    """Testa conexÃ£o com API compatÃ­vel"""
    print("ğŸ§ª Testando API compatÃ­vel com OpenAI...")
    
    # ConfiguraÃ§Ã£o de exemplo para ngrok
    base_url = "https://f00a89332e94.ngrok.app/v1/"
    model = "huihui-ai_-_qwen2.5-7b-instruct-abliterated-v2"
    api_key = "dummy-key"  # Muitas APIs locais nÃ£o precisam de key real
    
    print(f"ğŸ”— URL: {base_url}")
    print(f"ğŸ¤– Modelo: {model}")
    
    try:
        # Inicializa cliente
        client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        
        print("âœ… Cliente OpenAI inicializado")
        
        # Testa uma requisiÃ§Ã£o simples
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "VocÃª Ã© um assistente Ãºtil."},
                {"role": "user", "content": "OlÃ¡! Como vocÃª estÃ¡?"}
            ],
            max_tokens=100,
            temperature=0.7
        )
        
        print("âœ… RequisiÃ§Ã£o bem-sucedida!")
        print(f"ğŸ“ Resposta: {response.choices[0].message.content}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro: {e}")
        return False

def test_with_env_vars():
    """Testa usando variÃ¡veis de ambiente"""
    print("\nğŸŒ Testando com variÃ¡veis de ambiente...")
    
    base_url = os.getenv("OPENAI_BASE_URL")
    model = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
    api_key = os.getenv("OPENAI_API_KEY", "dummy-key")
    
    if not base_url:
        print("âš ï¸ OPENAI_BASE_URL nÃ£o configurada")
        return False
    
    print(f"ğŸ”— URL: {base_url}")
    print(f"ğŸ¤– Modelo: {model}")
    
    try:
        client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": "Teste de conexÃ£o"}
            ],
            max_tokens=50
        )
        
        print("âœ… Teste com variÃ¡veis de ambiente bem-sucedido!")
        print(f"ğŸ“ Resposta: {response.choices[0].message.content}")
        return True
        
    except Exception as e:
        print(f"âŒ Erro: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ¯ Teste de API CompatÃ­vel com OpenAI")
    print("=" * 50)
    
    # Teste com configuraÃ§Ã£o hard-coded
    success1 = test_openai_compatible_api()
    
    # Teste com variÃ¡veis de ambiente
    success2 = test_with_env_vars()
    
    print("\n" + "=" * 50)
    if success1 or success2:
        print("ğŸ‰ Pelo menos um teste foi bem-sucedido!")
        print("âœ… Sua API compatÃ­vel estÃ¡ funcionando!")
    else:
        print("âŒ Ambos os testes falharam")
        print("ğŸ’¡ Verifique:")
        print("   - URL da API estÃ¡ correta")
        print("   - Servidor estÃ¡ rodando")
        print("   - Modelo estÃ¡ disponÃ­vel")
        print("   - Firewall nÃ£o estÃ¡ bloqueando") 