import streamlit as st
import sqlite3
import os
from datetime import datetime, timedelta
from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi
from openai import OpenAI
from typing import List, Dict, Optional
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re

# ConfiguraÃ§Ãµes
YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY") or "AIzaSyCxwP28gezkKP2uk9Kw6O6b9SlK7foRlqE"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")  # Configure sua chave OpenAI
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL")  # URL customizada para APIs compatÃ­veis
OPENAI_MODEL = os.getenv("OPENAI_MODEL") or "gpt-3.5-turbo"  # Modelo customizado
DB_NAME = "transcripts.db"
MAX_RESULTS = 10

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="YouTube AI Chat",
    page_icon="ğŸ¥",
    layout="wide"
)

# Inicializar OpenAI
openai_client = None
if OPENAI_API_KEY or OPENAI_BASE_URL:
    # ConfiguraÃ§Ã£o para APIs OpenAI compatÃ­veis
    client_config = {}
    
    if OPENAI_API_KEY:
        client_config["api_key"] = OPENAI_API_KEY
    else:
        # Para APIs locais que nÃ£o precisam de key, usa uma dummy
        client_config["api_key"] = "dummy-key"
    
    if OPENAI_BASE_URL:
        client_config["base_url"] = OPENAI_BASE_URL
    
    openai_client = OpenAI(**client_config)

def create_openai_client(api_key: str, base_url: Optional[str] = None) -> Optional[OpenAI]:
    """Cria cliente OpenAI de forma segura."""
    try:
        if base_url:
            return OpenAI(api_key=api_key, base_url=base_url)
        else:
            return OpenAI(api_key=api_key)
    except Exception as e:
        st.error(f"Erro ao criar cliente OpenAI: {e}")
        return None

class YouTubeRAGSystem:
    def __init__(self):
        self.create_database()
        
    def create_database(self):
        """Cria o banco de dados SQLite."""
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS transcripts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id TEXT NOT NULL,
                title TEXT NOT NULL,
                topic TEXT NOT NULL,
                transcript TEXT,
                published_date TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        conn.commit()
        conn.close()

    def search_youtube_videos(self, topic: str) -> List[Dict]:
        """Busca vÃ­deos no YouTube."""
        youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)
        
        three_months_ago = datetime.now() - timedelta(days=90)
        published_after = three_months_ago.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        request = youtube.search().list(
            part="snippet",
            q=topic,
            type="video",
            maxResults=MAX_RESULTS,
            order="relevance",
            publishedAfter=published_after,
            regionCode="BR",
            relevanceLanguage="pt"
        )
        
        response = request.execute()
        videos = []
        
        for item in response["items"]:
            video_id = item["id"]["videoId"]
            title = item["snippet"]["title"]
            published_date = item["snippet"]["publishedAt"]
            videos.append({
                "video_id": video_id,
                "title": title,
                "published_date": published_date
            })
        
        return videos

    def get_transcript(self, video_id: str) -> Optional[str]:
        """ObtÃ©m transcriÃ§Ã£o de um vÃ­deo."""
        try:
            transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=["pt", "en"])
            return " ".join([entry["text"] for entry in transcript])
        except Exception as e:
            return None

    def process_videos(self, topic: str) -> int:
        """Processa vÃ­deos e salva transcriÃ§Ãµes."""
        videos = self.search_youtube_videos(topic)
        saved_count = 0
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, video in enumerate(videos):
            video_id = video["video_id"]
            title = video["title"]
            published_date = video["published_date"]
            
            status_text.text(f"Processando: {title[:50]}...")
            
            # Verifica se jÃ¡ existe no banco
            if not self.video_exists(video_id):
                transcript = self.get_transcript(video_id)
                
                if transcript:
                    self.save_transcript(video_id, title, topic, transcript, published_date)
                    saved_count += 1
            
            progress_bar.progress((i + 1) / len(videos))
        
        status_text.text(f"Processamento concluÃ­do! {saved_count} novas transcriÃ§Ãµes salvas.")
        return saved_count

    def video_exists(self, video_id: str) -> bool:
        """Verifica se o vÃ­deo jÃ¡ existe no banco."""
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM transcripts WHERE video_id = ?", (video_id,))
        exists = cursor.fetchone()[0] > 0
        conn.close()
        return exists

    def save_transcript(self, video_id: str, title: str, topic: str, transcript: str, published_date: str):
        """Salva transcriÃ§Ã£o no banco."""
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO transcripts (video_id, title, topic, transcript, published_date)
            VALUES (?, ?, ?, ?, ?)
        """, (video_id, title, topic, transcript, published_date))
        conn.commit()
        conn.close()

    def get_transcripts_by_topic(self, topic: str) -> List[Dict]:
        """ObtÃ©m transcriÃ§Ãµes por tÃ³pico."""
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()
        cursor.execute("""
            SELECT video_id, title, transcript, published_date 
            FROM transcripts 
            WHERE topic LIKE ? AND transcript IS NOT NULL
        """, (f"%{topic}%",))
        
        results = cursor.fetchall()
        conn.close()
        
        return [
            {
                "video_id": row[0],
                "title": row[1],
                "transcript": row[2],
                "published_date": row[3]
            }
            for row in results
        ]

    def find_relevant_context(self, query: str, topic: str, max_context: int = 3) -> str:
        """Encontra contexto relevante usando TF-IDF."""
        transcripts = self.get_transcripts_by_topic(topic)
        
        if not transcripts:
            return "Nenhuma transcriÃ§Ã£o encontrada para este tÃ³pico."
        
        # Prepara textos para vectorizaÃ§Ã£o
        documents = [t["transcript"] for t in transcripts]
        titles = [t["title"] for t in transcripts]
        
        # Se hÃ¡ poucos documentos, retorna todos
        if len(documents) <= max_context:
            context_parts = []
            for i, (title, doc) in enumerate(zip(titles, documents)):
                context_parts.append(f"**{title}**\n{doc[:800]}...")
            return "\n\n".join(context_parts)
        
        try:
            # Adiciona a query aos documentos
            all_docs = documents + [query.lower()]
            
            # VectorizaÃ§Ã£o TF-IDF com configuraÃ§Ãµes para portuguÃªs
            vectorizer = TfidfVectorizer(
                max_features=1000,
                stop_words=None,  # Remove stop_words especÃ­ficas
                min_df=1,
                ngram_range=(1, 2)  # Inclui bigramas
            )
            tfidf_matrix = vectorizer.fit_transform(all_docs)
            
            # Calcula similaridade entre query e documentos
            query_vec = tfidf_matrix[-1]  # Ãšltimo Ã© a query
            doc_vecs = tfidf_matrix[:-1]  # Todos exceto a query
            
            similarities = cosine_similarity(query_vec, doc_vecs).flatten()
            
            # Ordena por similaridade
            top_indices = similarities.argsort()[-max_context:][::-1]
            
            # ConstrÃ³i contexto com threshold mais baixo
            context_parts = []
            for idx in top_indices:
                if similarities[idx] > 0.01:  # Threshold muito menor
                    context_parts.append(f"**{titles[idx]}**\n{documents[idx][:800]}...")
            
            # Se ainda nÃ£o encontrou nada, pega os melhores mesmo assim
            if not context_parts:
                for idx in top_indices[:max_context]:
                    context_parts.append(f"**{titles[idx]}**\n{documents[idx][:800]}...")
                    
            return "\n\n".join(context_parts) if context_parts else "Erro na busca de contexto."
            
        except Exception as e:
            # Fallback: retorna os primeiros documentos
            context_parts = []
            for i, (title, doc) in enumerate(zip(titles[:max_context], documents[:max_context])):
                context_parts.append(f"**{title}**\n{doc[:800]}...")
            return "\n\n".join(context_parts)

    def chat_with_openai(self, query: str, context: str) -> str:
        """Chat com OpenAI usando contexto RAG."""
        # Usa o cliente do session_state se disponÃ­vel, senÃ£o usa o global
        client = getattr(st.session_state, 'openai_client', None) or openai_client
        model = getattr(st.session_state, 'current_model', None) or OPENAI_MODEL
        
        if not client:
            return "Por favor, configure sua API OpenAI ou compatÃ­vel."
        
        prompt = f"""
        VocÃª Ã© um assistente especializado em responder perguntas baseadas em transcriÃ§Ãµes de vÃ­deos do YouTube.
        
        CONTEXTO (das transcriÃ§Ãµes dos vÃ­deos):
        {context}
        
        PERGUNTA DO USUÃRIO: {query}
        
        Responda de forma Ãºtil e informativa, baseando-se principalmente no contexto fornecido. 
        Se a informaÃ§Ã£o nÃ£o estiver no contexto, mencione isso claramente.
        """
        
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "VocÃª Ã© um assistente especializado em analisar conteÃºdo de vÃ­deos do YouTube."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            return response.choices[0].message.content or "Desculpe, nÃ£o consegui gerar uma resposta."
        except Exception as e:
            return f"Erro ao comunicar com a API: {str(e)}"

class DeepResearchSystem:
    def __init__(self, rag_system):
        self.rag_system = rag_system
    
    def analyze_individual_video(self, video_data: Dict, research_query: str) -> Dict:
        """Analisa um vÃ­deo individual para extrair insights especÃ­ficos."""
        client = getattr(st.session_state, 'openai_client', None) or openai_client
        model = getattr(st.session_state, 'current_model', None) or OPENAI_MODEL
        
        if not client:
            return {"error": "Cliente OpenAI nÃ£o configurado"}
        
        # Pega uma amostra do transcript para anÃ¡lise
        transcript_sample = video_data["transcript"][:3000]  # Primeiros 3000 chars
        
        analysis_prompt = f"""
        VocÃª Ã© um pesquisador especializado em anÃ¡lise de conteÃºdo de vÃ­deos.
        
        VÃDEO ANALISADO: {video_data["title"]}
        
        TRANSCRIÃ‡ÃƒO (AMOSTRA):
        {transcript_sample}
        
        PERGUNTA DE PESQUISA: {research_query}
        
        Por favor, analise este vÃ­deo e extraia:
        1. **INSIGHTS PRINCIPAIS**: 3-5 pontos principais relacionados Ã  pergunta
        2. **DADOS/ESTATÃSTICAS**: NÃºmeros, fatos concretos mencionados
        3. **OPINIÃ•ES/PERSPECTIVAS**: Pontos de vista Ãºnicos do autor
        4. **EXEMPLOS PRÃTICOS**: Casos ou exemplos especÃ­ficos
        5. **RELEVÃ‚NCIA**: Como este vÃ­deo contribui para responder a pergunta (1-10)
        
        Seja especÃ­fico e objetivo. Foque apenas no que Ã© relevante para a pergunta de pesquisa.
        """
        
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "VocÃª Ã© um analista de conteÃºdo especializado em extrair insights de vÃ­deos do YouTube."},
                    {"role": "user", "content": analysis_prompt}
                ],
                max_tokens=800,
                temperature=0.3  # Mais determinÃ­stico para anÃ¡lise
            )
            
            return {
                "video_id": video_data["video_id"],
                "title": video_data["title"],
                "analysis": response.choices[0].message.content,
                "status": "success"
            }
            
        except Exception as e:
            return {
                "video_id": video_data["video_id"],
                "title": video_data["title"],
                "error": str(e),
                "status": "error"
            }
    
    def synthesize_insights(self, analyses: List[Dict], research_query: str, output_type: str) -> str:
        """Sintetiza todos os insights em um resultado final."""
        client = getattr(st.session_state, 'openai_client', None) or openai_client
        model = getattr(st.session_state, 'current_model', None) or OPENAI_MODEL
        
        if not client:
            return "Erro: Cliente OpenAI nÃ£o configurado"
        
        # Prepara o contexto com todas as anÃ¡lises
        context = "## ANÃLISES INDIVIDUAIS DOS VÃDEOS:\n\n"
        for i, analysis in enumerate(analyses, 1):
            if analysis["status"] == "success":
                context += f"### VÃDEO {i}: {analysis['title']}\n"
                context += f"{analysis['analysis']}\n\n"
        
        # Templates para diferentes tipos de saÃ­da
        templates = {
            "script": """
            Crie um SCRIPT DE VÃDEO profissional baseado nas anÃ¡lises. O script deve:
            - Ter introduÃ§Ã£o cativante
            - Desenvolver os pontos principais de forma lÃ³gica
            - Incluir dados e exemplos das anÃ¡lises
            - Ter transiÃ§Ãµes naturais entre tÃ³picos
            - Terminar com conclusÃ£o impactante
            - DuraÃ§Ã£o estimada: 5-8 minutos
            
            Formato: [INTRODUÃ‡ÃƒO] [DESENVOLVIMENTO] [CONCLUSÃƒO]
            """,
            
            "resumo": """
            Crie um RESUMO EXECUTIVO abrangente que:
            - Sintetize os principais insights
            - Destaque consensus e divergÃªncias
            - Inclua dados e estatÃ­sticas relevantes
            - Apresente conclusÃµes claras
            - Sugira prÃ³ximos passos ou recomendaÃ§Ãµes
            
            Formato: Texto corrido, bem estruturado e profissional
            """,
            
            "analise": """
            FaÃ§a uma ANÃLISE PROFUNDA que:
            - Compare diferentes perspectivas dos vÃ­deos
            - Identifique padrÃµes e tendÃªncias
            - Analise lacunas ou contradiÃ§Ãµes
            - Avalie a qualidade das fontes
            - ForneÃ§a insights Ãºnicos baseados na sÃ­ntese
            
            Formato: AnÃ¡lise acadÃªmica estruturada
            """,
            
            "artigo": """
            Escreva um ARTIGO COMPLETO que:
            - Tenha tÃ­tulo atrativo
            - Introduza o tema de forma envolvente
            - Desenvolva argumentos com base nas anÃ¡lises
            - Use dados e exemplos dos vÃ­deos
            - Inclua subtÃ³picos bem organizados
            - Termine com reflexÃµes finais
            
            Formato: Artigo de blog profissional
            """
        }
        
        synthesis_prompt = f"""
        VocÃª Ã© um pesquisador sÃªnior especializado em sÃ­ntese de informaÃ§Ãµes.
        
        PERGUNTA DE PESQUISA: {research_query}
        
        TIPO DE SAÃDA SOLICITADA: {output_type.upper()}
        
        CONTEXTO COM ANÃLISES:
        {context}
        
        INSTRUÃ‡ÃƒO ESPECÃFICA:
        {templates.get(output_type, templates["resumo"])}
        
        Com base nas anÃ¡lises individuais dos vÃ­deos, crie um {output_type} abrangente que responda Ã  pergunta de pesquisa de forma completa e profissional. Use os insights, dados e exemplos extraÃ­dos das anÃ¡lises para fundamentar sua resposta.
        """
        
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": f"VocÃª Ã© um especialista em criar {output_type}s profissionais baseados em pesquisa de mÃºltiplas fontes."},
                    {"role": "user", "content": synthesis_prompt}
                ],
                max_tokens=2000,
                temperature=0.4
            )
            
            return response.choices[0].message.content or f"Erro ao gerar {output_type}"
            
        except Exception as e:
            return f"Erro na sÃ­ntese: {str(e)}"
    
    def identify_research_gaps(self, analyses: List[Dict], research_query: str) -> List[str]:
        """Identifica pontos que precisam de mais aprofundamento."""
        client = getattr(st.session_state, 'openai_client', None) or openai_client
        model = getattr(st.session_state, 'current_model', None) or OPENAI_MODEL
        
        if not client:
            return []
        
        # Prepara contexto das anÃ¡lises
        context = "## ANÃLISES REALIZADAS:\n\n"
        for i, analysis in enumerate(analyses, 1):
            if analysis["status"] == "success":
                context += f"### VÃDEO {i}: {analysis['title']}\n"
                context += f"{analysis['analysis'][:500]}...\n\n"
        
        gap_analysis_prompt = f"""
        VocÃª Ã© um pesquisador especializado em identificar lacunas de conhecimento.
        
        PERGUNTA DE PESQUISA: {research_query}
        
        ANÃLISES ATUAIS:
        {context}
        
        Com base nas anÃ¡lises realizadas, identifique 3-5 PONTOS ESPECÃFICOS que precisam de mais aprofundamento para responder completamente Ã  pergunta de pesquisa.
        
        Para cada ponto, forneÃ§a:
        1. **TÃ³pico especÃ­fico** (mÃ¡ximo 6 palavras)
        2. **Por que precisa ser aprofundado** (1 frase)
        
        Formato de resposta:
        PONTO 1: [tÃ³pico especÃ­fico]
        RAZÃƒO: [por que precisa ser aprofundado]
        
        PONTO 2: [tÃ³pico especÃ­fico]
        RAZÃƒO: [por que precisa ser aprofundado]
        
        Seja especÃ­fico e focado em aspectos que realmente faltam na anÃ¡lise atual.
        """
        
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "VocÃª Ã© um especialista em identificar lacunas de pesquisa e pontos que precisam de aprofundamento."},
                    {"role": "user", "content": gap_analysis_prompt}
                ],
                max_tokens=600,
                temperature=0.3
            )
            
            response_text = response.choices[0].message.content or ""
            
            # Extrai pontos especÃ­ficos da resposta
            gaps = []
            lines = response_text.split('\n')
            current_point = None
            current_reason = None
            
            for line in lines:
                line = line.strip()
                if line.startswith("PONTO"):
                    if current_point and current_reason:
                        gaps.append(f"{current_point} ({current_reason})")
                    # Extrai o tÃ³pico apÃ³s os dois pontos
                    current_point = line.split(":", 1)[1].strip() if ":" in line else line
                    current_reason = None
                elif line.startswith("RAZÃƒO"):
                    current_reason = line.split(":", 1)[1].strip() if ":" in line else line
            
            # Adiciona o Ãºltimo ponto se existir
            if current_point and current_reason:
                gaps.append(f"{current_point} ({current_reason})")
            
            return gaps[:5]  # MÃ¡ximo 5 pontos
            
        except Exception as e:
            st.warning(f"Erro ao identificar lacunas: {e}")
            return []

    def search_focused_videos(self, focus_topic: str, original_topic: str) -> List[Dict]:
        """Busca vÃ­deos focados em um tÃ³pico especÃ­fico."""
        youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)
        
        # Combina o tÃ³pico original com o foco especÃ­fico
        search_query = f"{original_topic} {focus_topic}"
        
        three_months_ago = datetime.now() - timedelta(days=90)
        published_after = three_months_ago.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        try:
            request = youtube.search().list(
                part="snippet",
                q=search_query,
                type="video",
                maxResults=5,  # Menos vÃ­deos, mais especÃ­ficos
                order="relevance",
                publishedAfter=published_after,
                regionCode="BR",
                relevanceLanguage="pt"
            )
            
            response = request.execute()
            videos = []
            
            for item in response["items"]:
                video_id = item["id"]["videoId"]
                title = item["snippet"]["title"]
                published_date = item["snippet"]["publishedAt"]
                
                # Verifica se jÃ¡ temos este vÃ­deo no banco
                if not self.rag_system.video_exists(video_id):
                    transcript = self.rag_system.get_transcript(video_id)
                    if transcript:
                        # Salva no banco
                        self.rag_system.save_transcript(video_id, title, search_query, transcript, published_date)
                        videos.append({
                            "video_id": video_id,
                            "title": title,
                            "transcript": transcript,
                            "published_date": published_date
                        })
            
            return videos
            
        except Exception as e:
            st.error(f"Erro ao buscar vÃ­deos focados: {e}")
            return []

    def conduct_deep_research(self, topic: str, research_query: str, output_type: str) -> Dict:
        """Conduz uma pesquisa profunda completa."""
        
        # Passo 1: Obter vÃ­deos relacionados
        st.write("### ğŸ” Passo 1: Buscando vÃ­deos relacionados...")
        transcripts = self.rag_system.get_transcripts_by_topic(topic)
        
        if not transcripts:
            return {
                "status": "error",
                "message": f"Nenhum vÃ­deo encontrado para o tÃ³pico '{topic}'. FaÃ§a uma busca primeiro."
            }
        
        st.write(f"âœ… Encontrados {len(transcripts)} vÃ­deos para anÃ¡lise")
        
        # Passo 2: AnÃ¡lise individual de cada vÃ­deo
        st.write("### ğŸ§  Passo 2: Analisando cada vÃ­deo individualmente...")
        
        analyses = []
        progress_bar = st.progress(0)
        
        for i, video in enumerate(transcripts):
            st.write(f"ğŸ¥ Analisando: {video['title'][:60]}...")
            
            analysis = self.analyze_individual_video(video, research_query)
            analyses.append(analysis)
            
            # Mostra o progresso
            progress_bar.progress((i + 1) / len(transcripts))
            
            # Mostra resultado da anÃ¡lise individual
            if analysis["status"] == "success":
                with st.expander(f"ğŸ“Š AnÃ¡lise: {video['title'][:50]}..."):
                    st.write(analysis["analysis"])
            else:
                st.warning(f"âš ï¸ Erro na anÃ¡lise: {analysis.get('error', 'Erro desconhecido')}")
        
        successful_analyses = [a for a in analyses if a["status"] == "success"]
        
        if not successful_analyses:
            return {
                "status": "error",
                "message": "Nenhuma anÃ¡lise foi bem-sucedida. Verifique a configuraÃ§Ã£o da API."
            }
        
        # Passo 3: Identificar lacunas de pesquisa
        st.write("### ğŸ”¬ Passo 3: Identificando pontos para aprofundamento...")
        
        research_gaps = self.identify_research_gaps(successful_analyses, research_query)
        
        if research_gaps:
            st.write("ğŸ¯ **Pontos identificados que podem ser aprofundados:**")
            for i, gap in enumerate(research_gaps, 1):
                st.write(f"   {i}. {gap}")
            
            # Interface para seleÃ§Ã£o de pontos para aprofundar
            st.write("### ğŸ¤” Deseja aprofundar algum destes pontos?")
            
            selected_gaps = []
            cols = st.columns(min(len(research_gaps), 3))
            
            for i, gap in enumerate(research_gaps):
                with cols[i % 3]:
                    gap_topic = gap.split(" (")[0]  # Remove a razÃ£o para mostrar sÃ³ o tÃ³pico
                    if st.button(f"ğŸ” Aprofundar: {gap_topic}", key=f"gap_{i}"):
                        selected_gaps.append(gap_topic)
            
            # Se usuÃ¡rio selecionou pontos para aprofundar
            if selected_gaps:
                st.write("### ğŸ“š Passo 4: Buscando conteÃºdo adicional...")
                
                additional_analyses = []
                for gap_topic in selected_gaps:
                    st.write(f"ğŸ¯ Buscando vÃ­deos sobre: **{gap_topic}**")
                    
                    focused_videos = self.search_focused_videos(gap_topic, topic)
                    
                    if focused_videos:
                        st.write(f"   âœ… Encontrados {len(focused_videos)} vÃ­deos especÃ­ficos")
                        
                        for video in focused_videos:
                            analysis = self.analyze_individual_video(video, f"{research_query} - foco em {gap_topic}")
                            if analysis["status"] == "success":
                                additional_analyses.append(analysis)
                                st.write(f"   ğŸ“Š Analisado: {video['title'][:50]}...")
                    else:
                        st.write(f"   âš ï¸ Nenhum vÃ­deo adicional encontrado para {gap_topic}")
                
                # Combina anÃ¡lises originais com as adicionais
                if additional_analyses:
                    st.write(f"âœ… Adicionadas {len(additional_analyses)} anÃ¡lises especÃ­ficas")
                    successful_analyses.extend(additional_analyses)
                
                st.write("### ğŸ”— Passo 5: SÃ­ntese final expandida...")
            else:
                st.write("### ğŸ”— Passo 4: SÃ­ntese final...")
        else:
            st.write("### ğŸ”— Passo 4: SÃ­ntese final...")
        
        st.write(f"âœ… Sintetizando insights de {len(successful_analyses)} anÃ¡lises...")
        
        final_result = self.synthesize_insights(successful_analyses, research_query, output_type)
        
        return {
            "status": "success",
            "analyses_count": len(successful_analyses),
            "total_videos": len(transcripts),
            "final_result": final_result,
            "individual_analyses": successful_analyses,
            "research_gaps": research_gaps if research_gaps else []
        }

# Interface Streamlit
def main():
    st.title("ğŸ¥ YouTube AI Chat com RAG")
    st.markdown("Busque vÃ­deos do YouTube e converse sobre o conteÃºdo usando IA!")
    
    rag_system = YouTubeRAGSystem()
    
    # Inicializar configuraÃ§Ãµes no session_state
    if "api_configured" not in st.session_state:
        st.session_state.api_configured = bool(OPENAI_API_KEY or OPENAI_BASE_URL)
        st.session_state.api_type = "OpenAI Official" if OPENAI_API_KEY else "OpenAI Compatible"
        st.session_state.openai_client = openai_client
        st.session_state.current_model = OPENAI_MODEL
        st.session_state.current_base_url = OPENAI_BASE_URL

    # Sidebar para configuraÃ§Ãµes
    with st.sidebar:
        st.header("âš™ï¸ ConfiguraÃ§Ãµes")
        
        # ConfiguraÃ§Ãµes da API
        st.subheader("ğŸ¤– API Configuration")
        
        if not st.session_state.api_configured:
            st.warning("âš ï¸ Configure sua API OpenAI ou compatÃ­vel")
            
            # OpÃ§Ãµes de configuraÃ§Ã£o
            api_type = st.selectbox(
                "Tipo de API:",
                ["OpenAI Official", "OpenAI Compatible (Local/Custom)"],
                key="api_type_selector"
            )
            
            if api_type == "OpenAI Official":
                openai_key = st.text_input(
                    "OpenAI API Key", 
                    type="password",
                    key="openai_key_input"
                )
                if openai_key:
                    client = create_openai_client(openai_key)
                    if client:
                        st.session_state.openai_client = client
                        st.session_state.current_model = "gpt-3.5-turbo"
                        st.session_state.current_base_url = None
                        st.session_state.api_configured = True
                        st.session_state.api_type = "OpenAI Official"
                        st.success("âœ… OpenAI configurado")
                        st.rerun()
            else:
                custom_url = st.text_input(
                    "Base URL:", 
                    placeholder="http://localhost:1234/v1/ ou https://your-api.ngrok.app/v1/",
                    key="custom_url_input"
                )
                custom_model = st.text_input(
                    "Nome do Modelo:", 
                    placeholder="huihui-ai_-_qwen2.5-7b-instruct-abliterated-v2",
                    key="custom_model_input"
                )
                custom_key = st.text_input(
                    "API Key (opcional):", 
                    type="password",
                    help="Deixe vazio se a API local nÃ£o precisar de key",
                    key="custom_key_input"
                )
                
                if custom_url and custom_model:
                    api_key = custom_key if custom_key else "dummy-key"
                    client = create_openai_client(api_key, custom_url)
                    
                    if client:
                        st.session_state.openai_client = client
                        st.session_state.current_model = custom_model
                        st.session_state.current_base_url = custom_url
                        st.session_state.api_configured = True
                        st.session_state.api_type = "OpenAI Compatible"
                        st.success(f"âœ… API Customizada configurada")
                        st.info(f"ğŸ”— URL: {custom_url}")
                        st.info(f"ğŸ¤– Modelo: {custom_model}")
                        st.rerun()
        else:
            # Mostra configuraÃ§Ã£o atual
            if st.session_state.api_type == "OpenAI Compatible":
                st.success("âœ… API Customizada configurada")
                st.info(f"ğŸ”— URL: {st.session_state.current_base_url}")
                st.info(f"ğŸ¤– Modelo: {st.session_state.current_model}")
            else:
                st.success("âœ… OpenAI Oficial configurada")
                st.info(f"ğŸ¤– Modelo: {st.session_state.current_model}")
            
            # BotÃ£o para reconfigurar
            if st.button("ğŸ”„ Reconfigurar API"):
                st.session_state.api_configured = False
                st.session_state.openai_client = None
                st.rerun()
        
        st.markdown("---")
        st.markdown("### ğŸ“Š EstatÃ­sticas")
        
        # Mostrar estatÃ­sticas do banco
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM transcripts")
        total_transcripts = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(DISTINCT topic) FROM transcripts")
        total_topics = cursor.fetchone()[0]
        conn.close()
        
        st.metric("Total de TranscriÃ§Ãµes", total_transcripts)
        st.metric("TÃ³picos Ãšnicos", total_topics)
    
    # Tabs para diferentes funcionalidades
    tab1, tab2, tab3 = st.tabs(["ğŸ” Buscar VÃ­deos", "ğŸ’¬ Chat RÃ¡pido", "ğŸ§  Pesquisa Profunda"])
    
    with tab1:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.header("ğŸ” Buscar VÃ­deos")
            
            topic = st.text_input("Digite o assunto:", placeholder="Ex: inteligÃªncia artificial", key="search_topic")
            
            if st.button("ğŸš€ Buscar e Processar", type="primary"):
                if topic:
                    with st.spinner("Buscando vÃ­deos e processando transcriÃ§Ãµes..."):
                        saved_count = rag_system.process_videos(topic)
                    st.rerun()
                else:
                    st.warning("Por favor, digite um assunto.")
        
        with col2:
            # Mostrar vÃ­deos processados
            if topic:
                transcripts = rag_system.get_transcripts_by_topic(topic)
                if transcripts:
                    st.subheader(f"ğŸ“¹ VÃ­deos encontrados ({len(transcripts)})")
                    for t in transcripts[:8]:  # Mostra mais vÃ­deos
                        st.write(f"â€¢ {t['title'][:60]}...")
    
    with tab2:
        st.header("ğŸ’¬ Chat RÃ¡pido com IA")
        
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # Input do tÃ³pico para chat
        chat_topic = st.text_input("TÃ³pico para conversar:", value=topic if 'topic' in locals() else "", key="chat_topic")
        
        # Mostrar histÃ³rico do chat
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # Input do chat
        if prompt := st.chat_input("FaÃ§a uma pergunta sobre os vÃ­deos..."):
            if not chat_topic:
                st.warning("Primeiro digite um tÃ³pico!")
            else:
                # Adiciona mensagem do usuÃ¡rio
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # Busca contexto relevante
                with st.chat_message("assistant"):
                    with st.spinner("Pensando..."):
                        context = rag_system.find_relevant_context(prompt, chat_topic)
                        response = rag_system.chat_with_openai(prompt, context)
                    
                    st.markdown(response)
                    
                    # Mostra contexto usado (opcional)
                    with st.expander("ğŸ“ Ver contexto usado"):
                        st.text(context[:1000] + "..." if len(context) > 1000 else context)
                
                # Adiciona resposta do assistente
                st.session_state.messages.append({"role": "assistant", "content": response})
    
    with tab3:
        st.header("ğŸ§  Pesquisa Profunda")
        st.markdown("*AnÃ¡lise sistemÃ¡tica que simula o processo humano de pesquisa*")
        
        deep_research = DeepResearchSystem(rag_system)
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("ğŸ“‹ ConfiguraÃ§Ã£o da Pesquisa")
            
            research_topic = st.text_input(
                "TÃ³pico base:", 
                value=topic if 'topic' in locals() else "",
                placeholder="Ex: inteligÃªncia artificial",
                help="O tÃ³pico dos vÃ­deos que serÃ£o analisados",
                key="research_topic"
            )
            
            research_query = st.text_area(
                "Pergunta de pesquisa:",
                placeholder="Ex: Como a IA estÃ¡ impactando o mercado de trabalho? Quais sÃ£o os principais riscos e benefÃ­cios?",
                help="A pergunta especÃ­fica que vocÃª quer responder",
                height=100
            )
            
            output_type = st.selectbox(
                "Tipo de saÃ­da:",
                options=["resumo", "script", "analise", "artigo"],
                format_func=lambda x: {
                    "resumo": "ğŸ“„ Resumo Executivo",
                    "script": "ğŸ¥ Script de VÃ­deo", 
                    "analise": "ğŸ“Š AnÃ¡lise Profunda",
                    "artigo": "ğŸ“ Artigo Completo"
                }[x]
            )
        
        with col2:
            st.subheader("âš™ï¸ Processo Inteligente")
            st.write("**1.** ğŸ” Busca vÃ­deos relacionados")
            st.write("**2.** ğŸ§  Analisa cada vÃ­deo individualmente")
            st.write("**3.** ğŸ”¬ Identifica pontos para aprofundar")
            st.write("**4.** ğŸ¤” Pergunta se quer buscar mais conteÃºdo")
            st.write("**5.** ğŸ“š Busca vÃ­deos especÃ­ficos (opcional)")
            st.write("**6.** ğŸ”— SÃ­ntese final expandida")
            st.write("**7.** âœ¨ Gera conteÃºdo profissional")
            
            st.info("ğŸ’¡ **Novo**: O sistema identifica automaticamente lacunas e sugere aprofundamentos!")
            st.success("ğŸš€ **Resultado**: Pesquisa mais completa e detalhada")
        
        if st.button("ğŸš€ Iniciar Pesquisa Profunda", type="primary", key="deep_research_btn"):
            if not research_topic:
                st.error("âŒ Por favor, digite um tÃ³pico base")
            elif not research_query:
                st.error("âŒ Por favor, faÃ§a uma pergunta de pesquisa")
            else:
                st.divider()
                st.header("ğŸ”¬ Processo de Pesquisa em Andamento")
                
                # Executa a pesquisa profunda
                with st.spinner("Iniciando pesquisa profunda..."):
                    result = deep_research.conduct_deep_research(
                        topic=research_topic,
                        research_query=research_query,
                        output_type=output_type
                    )
                
                if result["status"] == "success":
                    st.success(f"âœ… Pesquisa concluÃ­da! Analisados {result['analyses_count']}/{result['total_videos']} vÃ­deos")
                    
                    st.divider()
                    st.header(f"ğŸ“‹ Resultado Final: {output_type.title()}")
                    
                    # Mostra o resultado final
                    st.markdown(result["final_result"])
                    
                    # BotÃ£o para baixar resultado
                    st.download_button(
                        label=f"â¬‡ï¸ Baixar {output_type.title()}",
                        data=result["final_result"],
                        file_name=f"{output_type}_{research_topic.replace(' ', '_')}.txt",
                        mime="text/plain"
                    )
                    
                    # Mostra estatÃ­sticas
                    with st.expander("ğŸ“Š EstatÃ­sticas da Pesquisa"):
                        st.metric("VÃ­deos Analisados", result['analyses_count'])
                        st.metric("Total de VÃ­deos Encontrados", result['total_videos'])
                        st.metric("Taxa de Sucesso", f"{(result['analyses_count']/result['total_videos']*100):.1f}%")
                
                else:
                    st.error(f"âŒ {result['message']}")

if __name__ == "__main__":
    main() 